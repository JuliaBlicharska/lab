{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorium 6.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuDa2xnt0kxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1k25iBl2JUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47mCBtOq2ONE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBg_ugR22YzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT8jZ5pk3giX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TndGzdhJBIOQ",
        "colab_type": "text"
      },
      "source": [
        "# Dane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3x-ZNeD4trL",
        "colab_type": "text"
      },
      "source": [
        "Stworzymy model, który będzie rozpoznawał czy dany tekst ma pozytywny czy negatywny wydźwięk (*sentiment analysis*). Korzystać będziemy z kolejnego \"standardowego\" zbioru danych: recenzje filmów z IMDB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_3FttLU4Kq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    # Use the version pre-encoded with an ~8k vocabulary.\n",
        "    'imdb_reviews/subwords8k', \n",
        "    # Return the train/test datasets as a tuple.\n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "    # Return (example, label) pairs from the dataset (instead of a dictionary).\n",
        "    as_supervised=True,\n",
        "    # Also return the `info` structure. \n",
        "    with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKzPB4Nh4b4p",
        "colab_type": "text"
      },
      "source": [
        "W ten sposób pobraliśmy:\n",
        "\n",
        "- dane do trenowania `train_data`\n",
        "- dane testowe `test_data`\n",
        "- dodatkową strukturę `info`\n",
        "\n",
        "Structura `info` zawiera w sobie funkcję wykorzystywaną do tłumaczenia (sub-)słów na liczby:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjAh49bz5fpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = info.features['text'].encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lessnfHF5h0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6njfVCFu5l1i",
        "colab_type": "text"
      },
      "source": [
        "Tyle sub-słów znajduje się w słowniku."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSBV7MCM50U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ehw = encoder.encode(\"Hello World!\")\n",
        "ehw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0zQqjzO54g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.decode(ehw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAFeyK3W59Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for token in ehw:\n",
        "  print(token, encoder.decode([token]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFwONH8L6CIi",
        "colab_type": "text"
      },
      "source": [
        "#### Zadanie\n",
        "\n",
        "Zbadaj strukturę zbioru danych do trenowania (`train_data`).\n",
        "\n",
        "\n",
        "1. Jak zakodowana jest etykietka?\n",
        "2. W jakim formacie jest recenzje?\n",
        "3. Wypisz kilka recenzji wraz z etykietką. Zobacz czy ma to sens?\n",
        "\n",
        "Przyda się funkcja `encoder.decode`.\n",
        "\n",
        "cf. https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHg5_Y-dBE-l",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "Zaczniemy od przygotowania danych do uczenia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b4CtnppBgSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL8G5gtoBstL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = (\n",
        "    train_data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32, train_data.output_shapes))\n",
        "\n",
        "test_batches = (\n",
        "    test_data\n",
        "    .padded_batch(32, train_data.output_shapes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XLx8kP1_Lef7"
      },
      "source": [
        "#### Zadanie\n",
        "\n",
        "Korzystając z dokumentacji [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) wyjaśnij poszczególne kroki służące przygotowaniu danych. Jak myślisz, jakie jest ich uzasadnienie?\n",
        "\n",
        "Wyjaśnij rozmiar poniższych batchy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzuvped2Lef4",
        "colab": {}
      },
      "source": [
        "for example_batch, label_batch in train_batches.take(2):\n",
        "  print(\"Batch shape:\", example_batch.shape)\n",
        "  print(\"label shape:\", label_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_66dnXLD7ru",
        "colab_type": "text"
      },
      "source": [
        "### Konstrukcja modelu\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lXfBpnTEfRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9k8v6jsHNFe",
        "colab_type": "text"
      },
      "source": [
        "`Embedding` jest wartwą, która dokonuje transformacji pojedynczej liczby na rzeczywisty 16-wymiarowy wektor. Jest to w istocie redukcja wymiaru z `encoder.vocab_size` (czyli 8000) do 16.\n",
        "\n",
        "[`GlobalAveragePooling1D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling1D) wylicza średnią wartość z poprzedniej warstwy (zwróć uwagę na zmianę kształtu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1T6zSgVGR_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mp5VG_nGSnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Vf03HQGdUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOqJ9rcYGpxY",
        "colab_type": "text"
      },
      "source": [
        "### Wykres parametrów uczenia\n",
        "\n",
        "Wizualizacja graficzna parametrów uczenia bywa przydatna.\n",
        "\n",
        "Przeanalizuj poniższy kod:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZKuuMd7Gofi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoNM6TnxGzi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyY82uCoG_OJ",
        "colab_type": "text"
      },
      "source": [
        "#### Zadanie\n",
        "\n",
        "Przeprowadź trenowanie dla większej liczby epok (np. 30, 50), narysuj jeszcze raz wykresy. Co możesz powiedzieć o overfittingu?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv5-4v23Ihek",
        "colab_type": "text"
      },
      "source": [
        "#### Zadanie\n",
        "\n",
        "Wykonaj eksperymenty z inną architekturą:\n",
        "\n",
        "- dodaj więcej warstw ukrytych o różnych szerokościach\n",
        "- zmień wymiar embeddingu\n",
        "\n",
        "Spróbuj zwiększyć dokładność modelu."
      ]
    }
  ]
}